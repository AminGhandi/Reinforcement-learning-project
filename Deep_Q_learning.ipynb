{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Q-learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9MOUorX0T2c9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import gym\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense , Activation ,Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "WMIkAgrFT9Ma"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'CartPole-v1'\n",
        "env = gym.make(env_name)"
      ],
      "metadata": {
        "id": "b-q_z0QgT-aG"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_observations = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.n"
      ],
      "metadata": {
        "id": "kgVlZ2DPU7Zw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WoDNo6cNkGqD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(16, input_shape=(1, num_observations)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(num_actions))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eogh3zRSUXF4",
        "outputId": "4d511548-c091-4150-a89f-ac1eb67dc03d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 1, 16)             80        \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 1, 16)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1, 32)             544       \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 1, 32)             0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1, 2)              66        \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 1, 2)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 690\n",
            "Trainable params: 690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_model = clone_model(model)"
      ],
      "metadata": {
        "id": "-Zs7pj7yV6jF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters and Update Function"
      ],
      "metadata": {
        "id": "euo7UZbafYzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "epsilon = 1.0\n",
        "EPSILON_REDUCE = 0.995 \n",
        "LEARNING_RATE = 0.001 \n",
        "GAMMA = 0.95\n"
      ],
      "metadata": {
        "id": "YgOARFdYWJKJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy_action_selection(model, epsilon, observation):\n",
        "    if np.random.random() > epsilon:\n",
        "        prediction = model.predict(observation)  \n",
        "        action = np.argmax(prediction)\n",
        "    else:\n",
        "        action = np.random.randint(0, env.action_space.n) \n",
        "    return action"
      ],
      "metadata": {
        "id": "kzOKeB-WYs8a"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = deque(maxlen=20000)\n",
        "update_target_model = 10\n",
        "\n",
        "def replay(replay_buffer, batch_size, model, target_model):\n",
        "    \n",
        "    # As long as the buffer has not enough elements we do nothing\n",
        "    if len(replay_buffer) < batch_size: \n",
        "        return\n",
        "    \n",
        "    # Take a random sample from the buffer with size batch_size\n",
        "    samples = random.sample(replay_buffer, batch_size)  \n",
        "    \n",
        "    target_batch = []     \n",
        "    zipped_samples = list(zip(*samples))  \n",
        "    states, actions, rewards, new_states, dones = zipped_samples  \n",
        "    \n",
        "    # Predict targets for all states from the sample\n",
        "    targets = target_model.predict(np.array(states))\n",
        "    \n",
        "    # Predict Q-Values for all new states from the sample\n",
        "    q_values = model.predict(np.array(new_states)) \n",
        "    # Now we loop over all predicted values to compute the actual targets\n",
        "    for i in range(batch_size):  \n",
        "        q_value = max(q_values[i][0])  \n",
        "        \n",
        "        target = targets[i].copy()  \n",
        "        if dones[i]:\n",
        "            target[0][actions[i]] = rewards[i]\n",
        "        else:\n",
        "            target[0][actions[i]] = rewards[i] + q_value * GAMMA\n",
        "        target_batch.append(target)\n",
        "\n",
        "    # Fit the model based on the states and the updated targets for 1 epoch\n",
        "    model.fit(np.array(states), np.array(target_batch), epochs=1, verbose=0)  "
      ],
      "metadata": {
        "id": "ZKFcv1YLfdJD"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update our target network every once in a while\n",
        "def update_model_handler(epoch, update_target_model, model, target_model):\n",
        "    if epoch > 0 and epoch % update_target_model == 0:\n",
        "        target_model.set_weights(model.get_weights())"
      ],
      "metadata": {
        "id": "h_zv6Ji7gkRP"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "W1IsPhXGg2gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer=Adam(learning_rate=LEARNING_RATE))\n"
      ],
      "metadata": {
        "id": "3WfjTVZDyVmV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_so_far = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    observation = env.reset()  # Get inital state\n",
        "    \n",
        "    # Keras expects the input to be of shape [1, X] thus we have to reshape\n",
        "    observation = observation.reshape([1, 4])  \n",
        "    done = False  \n",
        "    \n",
        "    points = 0\n",
        "    while not done:  # as long current run is active\n",
        "        \n",
        "        # Select action acc. to strategy\n",
        "        action = epsilon_greedy_action_selection(model, epsilon, observation)\n",
        "        \n",
        "        # Perform action and get next state\n",
        "        next_observation, reward, done, info = env.step(action)  \n",
        "        next_observation = next_observation.reshape([1, 4])  # Reshape!!\n",
        "        replay_buffer.append((observation, action, reward, next_observation, done))  # Update the replay buffer\n",
        "        observation = next_observation  # update the observation\n",
        "        points+=1\n",
        "\n",
        "        # Most important step! Training the model by replaying\n",
        "        replay(replay_buffer, 32, model, target_model)\n",
        "\n",
        "    \n",
        "    epsilon *= EPSILON_REDUCE  # Reduce epsilon\n",
        "    \n",
        "    # Check if we need to update the target model\n",
        "    update_model_handler(epoch, update_target_model, model, target_model)\n",
        "    \n",
        "    if points > best_so_far:\n",
        "        best_so_far = points\n",
        "    if epoch %25 == 0:\n",
        "        print(f\"{epoch}: Points reached: {points} - epsilon: {epsilon} - Best: {best_so_far}\")\n"
      ],
      "metadata": {
        "id": "4wg1uwFqhoFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aAO_1cBc2c__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}